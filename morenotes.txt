
not both neurons should have justsnapped=true
---
bug when reading long memory
--
prediction becomes weird after 2nd snapping (kitti)
--
noise: surprise should not become worse and worse, that's literally impossible
--
weights should be different after snap:
-always active at same time -> create pattern (even is not needed?)
-same proba but not same time -> actually additive
----
pattern neurons: add existing probas from input neurons
---
recalculate co-weights
---
save and load co-weights
---
need to take co-activation into consideration for bundle prediction
current age/value is mis-calculated for bundle

export GOOGLE_APPLICATION_CREDENTIALS=/Users/lana/Desktop/mfk/ddetox/DrJailer-9ca78901eef2.json

ya29.ElqHBOtWKUL9s6gt5ewp3pZWeGQIP-oZ8_HI7izodA0iIEQJBHV4CePepfrXkUz8oFzNUyex2HriBSLw4uCnm6htOkyiSmf_wwuce9cMGh0p3JwPHIj-gKrYK2w

curl -s -H "Content-Type: application/json" \
    -H "Authorization: Bearer ya29.ElqHBFfDMwIauUxXDHQawYlxp2CjcmGOkUUsC0tQmq0zdSM_Jkfcf5s-Bpf1gpqHX513vhoLitTuwnQv9tNc-dA9rA9uqrqe_fMcnQTuBrE1zJ8pWPpNg8SOGaU" \
    https://speech.googleapis.com/v1/speech:recognize \
    -d @sync-request.json

dream doesnt reach pattern neurons??

need a better thing than "age":
  when wrong, variability changes? or age is just fine
perf with and without patterns
radio button layer + sensors (so we can choose what we see)
see separate prediction maps?
actual computing time

need several time scales: same time scale = same level for pattern neurons
slower time scale = we can combine pattern neurons

cannot predict actions = cannot predict pattern neurons that have actions = cannot have predictions for "muted" neurons
So instead do not care that they are mute (until we have intentions?)

*save and load functions for network
could not see white in ecal
some weights are not updated after creating (individual) pattern neurons?
also too many weights remaining (probably because not updated)
why so much time to learn simple time series

1:48


ffmpeg -i Oswald_the_Lucky_Rabbit.mp4 -ss 01:47 -r 5/1 walk/$filename%03d.bmp



宮脇様

池上研究室のラナです。


1.紅莉栖の稼働率：直近3ヶ月の稼働率
私が行っていたプロジェクトの1つが、同じ池上研の別の学生が引き続きになって、最近ドワンゴさんのサーバーを使っていません。引き続きの人は、研究室のGPU machineを使っています。
もう1つは結果が出て終了しました。

2. 紅莉栖での成果：公開済みの成果, 論文タイトル,これまでに紅莉栖で行った実験の概要などをお書きください.
人工知能学会2017の発表：Video Compression with a Predictive Neural Network
ビデオframeを予測する深層学習ネットワーク「Prednet」を、そのままビデオ圧縮に使ってmpeg4圧縮との効率と比べた研究。Prednetの予測はmpeg4の予測エンジンより効率が高く、予測のエラー率が低いが、予測のエラー自体は圧縮しにくいという結果になりました。


3. 継続利用希望　：継続して利用されたい方は、期限と目的を改めてお書きください

継続を希望しません。面白い研究ができてドワンゴさんに感謝しています。



mogrify -resize 10% *.png  Lanas-MacBook-Pro:Dataset_01
mogrify -chop 4x0+0+0 -gravity East *.png
mogrify -chop 30x0+0+0 -gravity West *.png 

//chop x pixels starting southeast
chop 5x10 -gravity Southeast x.JPG  

mogrify -resize 40% *.png
mogrify -chop 4x12 -gravity Northeast *.png


    ffmpeg -i Oswald_the_Lucky_Rabbit.mp4 -ss 01:47 -r 5/1 walk/$filename%03d.bmp
  convert '*.bmp[360x360+0+0]' small/%02d.bmp  

 convert 'small/*.bmp[50x>]' small/%02d.bmp 
 ffmpeg -r 5/1 -i %02d.bmp -c:v libx264 -vf fps=5/1 -pix_fmt yuv420p out.mp4 


Lanas-MacBook-Pro:small lana$ convert '*.bmp' ppm/%02d.ppm




$GPVTG,317.04,T,,M,0.92,N,1.71,K,A*30
$GPZDA,072915.000,26,06,2017,,*58
$GPGGA,072916.000,3539.6963,N,13941.0438,E,1,5,2.69,68.0,M,39.4,M,,*68
$GPGLL,3539.6963,N,13941.0438,E,072916.000,A,A*55
$GPGSA,A,3,01,28,22,11,03,,,,,,,,2.87,2.69,0.99*0A
$GPGSV,4,1,13,03,70,129,14,28,64,253,20,22,56,067,16,01,50,040,33*7E
$GPGSV,4,2,13,11,41,068,23,17,40,316,,19,19,306,,08,17,114,*7E
$GPGSV,4,3,13,06,12,258,,23,09,146,,14,04,049,,30,04,226,*70
$GPGSV,4,4,13,193,,,*40
$GPRMC,072916.000,A,3539.6963,N,13941.0438,E,0.92,322.81,260617,,,A*67
$GPVTG,322.81,T,,M,0.92,N,1.71,K,A*3B
$GPZDA,072916.000,26,06,2017,,*5B


58, 232

